{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOT3QxObpiXL+ibKxEEcrg4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaishnav221/File_Upload_View_Download/blob/main/File_Compression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6jV6xEw2nHR3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b477b0cc-ca9d-4f5a-d881-1f8d470d96cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the full path of the folder to compress: /content/Sample_folder\n",
            "Enter the full path of the folder to extract files: /content/Copy_Folder1\n",
            "Original Folder Contents (/content/Sample_folder): 10 files, 2534.27 KB\n",
            "Files compressed into compressed_files.bz2 using bz2.\n",
            "Original Size: 2534.27 KB, Compressed Size: 2442.91 KB\n",
            "Compression Ratio: 96.40%\n",
            "Compression Success: 3.60%\n",
            "Files extracted successfully using index mapping.\n",
            "Extracted Folder Size: 2534.27 KB, Number of Files: 10\n",
            "Extracted Folder Contents (/content/Copy_Folder1): 10 files, 2534.27 KB\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import tarfile\n",
        "import bz2\n",
        "import lzma\n",
        "import json\n",
        "import io\n",
        "\n",
        "def get_folder_size(folder):\n",
        "    total_size = 0\n",
        "    for dirpath, dirnames, filenames in os.walk(folder):\n",
        "        for f in filenames:\n",
        "            fp = os.path.join(dirpath, f)\n",
        "            total_size += os.path.getsize(fp)\n",
        "    return total_size, len(filenames)\n",
        "\n",
        "def show_folder_contents(folder, description):\n",
        "    if os.path.exists(folder):\n",
        "        files_list = sorted(os.listdir(folder))\n",
        "        total_size, num_files = get_folder_size(folder)\n",
        "        print(f\"{description} ({folder}): {num_files} files, {total_size / 1024:.2f} KB\")\n",
        "    else:\n",
        "        print(f\"{description} ({folder}) does not exist.\")\n",
        "\n",
        "def determine_compression_method(folder):\n",
        "    total_size, _ = get_folder_size(folder)\n",
        "    extensions = {os.path.splitext(f)[1].lower() for f in os.listdir(folder)}\n",
        "\n",
        "    if total_size > 100 * 1024 * 1024:\n",
        "        return \"tar.gz\"\n",
        "    elif {'.txt', '.csv', '.log'}.intersection(extensions):\n",
        "        return \"zip\"\n",
        "    elif total_size < 10 * 1024 * 1024:\n",
        "        return \"bz2\"\n",
        "    else:\n",
        "        return \"xz\"\n",
        "\n",
        "def compress_folder(input_folder, compression_method):\n",
        "    index_map = {}\n",
        "    compressed_file = \"\"\n",
        "    original_size, num_files = get_folder_size(input_folder)\n",
        "\n",
        "    if compression_method == \"zip\":\n",
        "        zip_filename = \"compressed_files.zip\"\n",
        "        with zipfile.ZipFile(zip_filename, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
        "            for idx, file in enumerate(sorted(os.listdir(input_folder), reverse=True)):\n",
        "                index_map[file] = str(idx)\n",
        "                zipf.write(os.path.join(input_folder, file), arcname=index_map[file])\n",
        "        compressed_file = zip_filename\n",
        "\n",
        "    elif compression_method == \"tar.gz\":\n",
        "        tar_filename = \"compressed_files.tar.gz\"\n",
        "        with tarfile.open(tar_filename, \"w:gz\") as tarf:\n",
        "            for idx, file in enumerate(sorted(os.listdir(input_folder), reverse=True)):\n",
        "                index_map[file] = str(idx)\n",
        "                tarf.add(os.path.join(input_folder, file), arcname=index_map[file])\n",
        "        compressed_file = tar_filename\n",
        "\n",
        "    elif compression_method == \"bz2\":\n",
        "        bz2_filename = \"compressed_files.bz2\"\n",
        "        with bz2.BZ2File(bz2_filename, \"w\") as bz2f:\n",
        "            for idx, file in enumerate(sorted(os.listdir(input_folder), reverse=True)):\n",
        "                # Add file to index_map before compressing\n",
        "                if os.path.isfile(os.path.join(input_folder, file)):\n",
        "                    index_map[file] = str(idx)\n",
        "                    with open(os.path.join(input_folder, file), \"rb\") as f:\n",
        "                        bz2f.write(f.read())\n",
        "        compressed_file = bz2_filename\n",
        "\n",
        "    elif compression_method == \"xz\":\n",
        "        xz_filename = \"compressed_files.xz\"\n",
        "        with lzma.open(xz_filename, \"w\") as xzf:\n",
        "            for idx, file in enumerate(sorted(os.listdir(input_folder), reverse=True)):\n",
        "                # Add file to index_map before compressing\n",
        "                if os.path.isfile(os.path.join(input_folder, file)):\n",
        "                    index_map[file] = str(idx)\n",
        "                    with open(os.path.join(input_folder, file), \"rb\") as f:\n",
        "                        xzf.write(f.read())\n",
        "        compressed_file = xz_filename\n",
        "\n",
        "\n",
        "    compressed_size = os.path.getsize(compressed_file)\n",
        "    compression_success = (1 - (compressed_size / original_size)) * 100\n",
        "\n",
        "    with open(\"index_map.json\", \"w\") as json_file:\n",
        "        json.dump(index_map, json_file)\n",
        "\n",
        "    print(f\"Files compressed into {compressed_file} using {compression_method}.\")\n",
        "    print(f\"Original Size: {original_size / 1024:.2f} KB, Compressed Size: {compressed_size / 1024:.2f} KB\")\n",
        "    print(f\"Compression Ratio: {compressed_size / original_size:.2%}\")\n",
        "    print(f\"Compression Success: {compression_success:.2f}%\")\n",
        "    return compressed_file, \"index_map.json\"\n",
        "\n",
        "def extract_folder(compressed_file, index_map_filename, output_folder):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    with open(index_map_filename, \"r\") as json_file:\n",
        "        index_map = json.load(json_file)\n",
        "    reverse_map = {str(v): k for k, v in index_map.items()}\n",
        "\n",
        "    if compressed_file.endswith(\".zip\"):\n",
        "        with zipfile.ZipFile(compressed_file, 'r') as zip_ref:\n",
        "            for file in zip_ref.namelist():\n",
        "                extracted_path = os.path.join(output_folder, reverse_map[file])\n",
        "                with open(extracted_path, \"wb\") as f:\n",
        "                    f.write(zip_ref.read(file))\n",
        "\n",
        "    elif compressed_file.endswith(\".tar.gz\"):\n",
        "        with tarfile.open(compressed_file, 'r:gz') as tar_ref:\n",
        "            for member in tar_ref.getmembers():\n",
        "                extracted_path = os.path.join(output_folder, reverse_map[member.name])\n",
        "                with open(extracted_path, \"wb\") as f:\n",
        "                    f.write(tar_ref.extractfile(member).read())\n",
        "    # Handle bz2 and xz extraction using index_map\n",
        "    elif compressed_file.endswith(\".bz2\") or compressed_file.endswith(\".xz\"):\n",
        "        with open(compressed_file, \"rb\") as compressed_f:\n",
        "            decompressed_data = bz2.decompress(compressed_f.read()) if compressed_file.endswith(\".bz2\") else lzma.decompress(compressed_f.read())\n",
        "            # Split the decompressed data based on file boundaries using index_map\n",
        "\n",
        "             # Wrap decompressed_data with io.BytesIO to treat it as a file-like object\n",
        "            data_stream = io.BytesIO(decompressed_data)\n",
        "\n",
        "            for idx, file in enumerate(sorted(index_map.keys(), key=lambda x: int(index_map[x]))):\n",
        "                extracted_path = os.path.join(output_folder, file)\n",
        "                # Write the file content\n",
        "                with open(extracted_path, \"wb\") as f:\n",
        "                     f.write(data_stream.read()) # Write the entire decompressed data, assuming single file in bz2/xz\n",
        "\n",
        "    extracted_size, num_files = get_folder_size(output_folder)\n",
        "    print(\"Files extracted successfully using index mapping.\")\n",
        "    print(f\"Extracted Folder Size: {extracted_size / 1024:.2f} KB, Number of Files: {num_files}\")\n",
        "    show_folder_contents(output_folder, \"Extracted Folder Contents\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_folder = input(\"Enter the full path of the folder to compress: \")\n",
        "    output_folder = input(\"Enter the full path of the folder to extract files: \")\n",
        "    show_folder_contents(input_folder, \"Original Folder Contents\")\n",
        "\n",
        "    compression_method = determine_compression_method(input_folder)\n",
        "    compressed_file, index_map_filename = compress_folder(input_folder, compression_method)\n",
        "    extract_folder(compressed_file, index_map_filename, output_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pglIiIZ_r_zc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}